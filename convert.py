import re
import json
import os
import sys

# å˜—è©¦åŒ¯å…¥å¿…è¦çš„åº«ï¼Œå¦‚æœæ²’æœ‰å®‰è£æœƒæç¤º
try:
    from docx import Document
except ImportError:
    Document = None

try:
    import pyphen
except ImportError:
    pyphen = None

class PetVocabProcessor:
    def __init__(self):
        # åˆå§‹åŒ–éŸ³ç¯€æ‹†è§£å·¥å…·
        if pyphen:
            self.dic = pyphen.Pyphen(lang='en')
        else:
            self.dic = None
            print("è­¦å‘Š: æœªå®‰è£ pyphenï¼Œå°‡ç„¡æ³•è‡ªå‹•æ‹†è§£éŸ³ç¯€ã€‚è«‹åŸ·è¡Œ pip install pyphen")

    def get_syllables(self, word: str) -> list:
        """
        å°‡å–®å­—æ‹†è§£ç‚ºéŸ³ç¯€åˆ—è¡¨
        ä¾‹å¦‚: 'ability' -> ['a', 'bil', 'i', 'ty']
        """
        if not self.dic or not word:
            return [word] # å¦‚æœæ²’å®‰è£å·¥å…·ï¼Œç›´æ¥å›å‚³åŸå­—
        
        # ç§»é™¤éå­—æ¯å­—ç¬¦ (é¿å…æ¨™é»ç¬¦è™Ÿå½±éŸ¿)
        clean_word = re.sub(r'[^a-zA-Z]', '', word)
        if not clean_word: return [word]
        
        hyphenated = self.dic.inserted(clean_word)
        return hyphenated.split('-')

    def clean_word_text(self, text):
        """
        æ¸…ç†å–®å­—æ–‡å­—ï¼šå»é™¤é–‹é ­çš„æ•¸å­—ã€é»ã€ç©ºç™½
        ä¾‹å¦‚: "1. ability " -> "ability"
        """
        # å»é™¤æ‹¬è™Ÿå…§çš„è©æ€§ (v.) (n.)
        text = re.sub(r'\(.*?\)', '', text)
        # å»é™¤é–‹é ­çš„æ•¸å­—å’Œé»
        text = re.sub(r'^[\d\.]+\s*', '', text)
        return text.strip()

    def parse_docx(self, filename):
        """
        è®€å– Word (.docx) æª”æ¡ˆ - å¼·åŠ›ç›¸å®¹ç‰ˆ
        """
        # 1. æª¢æŸ¥å¥—ä»¶
        if not Document:
            print("éŒ¯èª¤: å°šæœªå®‰è£ python-docxã€‚è«‹åŸ·è¡Œ pip install python-docx")
            return self.get_mock_data()

        # 2. æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if not os.path.exists(filename):
            print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: '{filename}'")
            print("è«‹ç¢ºèª Word æª”æ˜¯å¦æ”¾åœ¨åŒä¸€å€‹è³‡æ–™å¤¾ï¼Œä¸”åç¨±å®Œå…¨æ­£ç¢ºã€‚")
            return self.get_mock_data()

        print(f"ğŸ“‚ æ­£åœ¨è®€å–æª”æ¡ˆ: {filename} ...")
        try:
            document = Document(filename)
        except Exception as e:
            print(f"âŒ è®€å–æª”æ¡ˆå¤±æ•—: {e}")
            return self.get_mock_data()

        processed_data = []
        current_day = 1
        word_count = 0
        table_count = len(document.tables)
        
        if table_count > 0:
            print(f"ç™¼ç¾ {table_count} å€‹è¡¨æ ¼ï¼Œæ­£åœ¨è§£æ...")
            
            for t_idx, table in enumerate(document.tables):
                # æ¯å€‹è¡¨æ ¼å‰å¹¾è¡Œç¨å¾®å°å‡ºä¾† Debug
                # if t_idx == 0: print("æ­£åœ¨æª¢æŸ¥ç¬¬ä¸€å€‹è¡¨æ ¼çµæ§‹...")

                for r_idx, row in enumerate(table.rows):
                    cells = [cell.text.strip() for cell in row.cells]
                    
                    # éæ¿¾æ‰ç©ºè¡Œ
                    if not any(cells): 
                        continue
                    
                    row_text = "".join(cells)
                    
                    # åµæ¸¬å¤©æ•¸ (ä¾‹å¦‚ "Day 1" æˆ– "ç¬¬ 1 å¤©")
                    if "Day" in row_text or ("ç¬¬" in row_text and "å¤©" in row_text):
                        nums = re.findall(r'\d+', row_text)
                        if nums:
                            current_day = int(nums[0])
                            # print(f"--> åˆ‡æ›è‡³ç¬¬ {current_day} å¤©")
                        continue

                    # --- å¼·åŠ›è§£æé‚è¼¯ ---
                    word_cand = ""
                    ipa_cand = ""
                    mean_cand = ""
                    sent_cand = ""
                    
                    # ç­–ç•¥ï¼šé€æ ¼åˆ†æå…§å®¹ç‰¹æ€§
                    for cell_text in cells:
                        if not cell_text: continue
                        
                        # 1. å¦‚æœåŒ…å«ä¸­æ–‡ -> å¾ˆå¤§æ©Ÿç‡æ˜¯æ„æ€
                        if re.search(r'[\u4e00-\u9fff]', cell_text):
                            # å¦‚æœå­—æ•¸å¤ªå¤šï¼Œå¯èƒ½æ˜¯ä¾‹å¥çš„ä¸­æ–‡ç¿»è­¯ï¼Œé€™è£¡ç°¡å–®åˆ¤æ–·é•·åº¦
                            if len(cell_text) < 50:
                                if not mean_cand: mean_cand = cell_text
                            
                        # 2. å¦‚æœåŒ…å«éŸ³æ¨™ç¬¦è™Ÿ / æˆ– [ -> éŸ³æ¨™
                        elif ('/' in cell_text or '[' in cell_text) and len(cell_text) < 30:
                             if not ipa_cand: ipa_cand = cell_text

                        # 3. å¦‚æœæ˜¯è‹±æ–‡é•·å¥ (å«ç©ºæ ¼) -> ä¾‹å¥
                        elif len(cell_text.split()) > 3:
                            if not sent_cand: sent_cand = cell_text
                            
                        # 4. å¦‚æœæ˜¯è‹±æ–‡çŸ­å­— -> å¯èƒ½æ˜¯å–®å­—
                        # å…è¨±åŒ…å«ä¸€é»é›œè¨Š(å¦‚æ•¸å­—)ï¼Œç¨å¾Œæ¸…ç†
                        elif re.search(r'[a-zA-Z]', cell_text):
                            # æ’é™¤å¤ªçŸ­çš„ (å¦‚ç·¨è™Ÿ a, b) é™¤éæ˜¯ a, I ç­‰å­—
                            clean_text = self.clean_word_text(cell_text)
                            if len(clean_text) >= 1:
                                if not word_cand: word_cand = clean_text

                    # åªè¦æœ‰æŠ“åˆ°å–®å­—ï¼Œæˆ‘å€‘å°±æ”¶éŒ„ (å³ä½¿æ²’æœ‰æ„æ€æˆ–ä¾‹å¥)
                    if word_cand:
                        # æ’é™¤æ¨™é¡Œè¡Œ (ä¾‹å¦‚æ¨™é¡Œå°±æ˜¯ "Word")
                        if word_cand.lower() in ['word', 'vocabulary', 'å–®å­—']:
                            continue
                            
                        word_count += 1
                        # å¦‚æœæ˜¯å‰å¹¾ç­†ï¼Œå°å‡ºä¾†è®“ç”¨æˆ¶å®‰å¿ƒ
                        if word_count <= 3:
                            print(f"   [ç¯„ä¾‹] æŠ“åˆ°: {word_cand} ({mean_cand})")

                        entry = {
                            "id": word_count,
                            "day_number": current_day,
                            "word": word_cand,
                            "ipa": ipa_cand,
                            "meaning": mean_cand or "è‡ªè¨‚", # é˜²å‘†
                            "sentence": sent_cand or f"Example for {word_cand}", # é˜²å‘†
                            "syllables": self.get_syllables(word_cand)
                        }
                        processed_data.append(entry)

        else:
            print("âš ï¸ æœªç™¼ç¾è¡¨æ ¼ï¼Œè«‹ç¢ºèª Word æª”æ˜¯å¦ä½¿ç”¨è¡¨æ ¼æ’ç‰ˆã€‚")

        if not processed_data:
            print("âš ï¸ ä¾ç„¶æ²’æœ‰æŠ“åˆ°å–®å­—ã€‚")
            print("å¯èƒ½åŸå› ï¼šè¡¨æ ¼æ ¼å¼å¤ªç‰¹æ®Šã€‚")
            return self.get_mock_data()

        return processed_data

    def get_mock_data(self):
        """ç”Ÿæˆç¯„ä¾‹è³‡æ–™ (å‚™ç”¨)"""
        print("--> ç”Ÿæˆ 4 ç­†æ¨¡æ“¬è³‡æ–™...")
        return [
            {"id":1, "day_number":1, "word":"ability", "ipa":"/É™ËˆbÉªlÉ™ti/", "meaning":"èƒ½åŠ›", "sentence":"She has the ability...", "syllables":["a","bil","i","ty"]},
            {"id":2, "day_number":1, "word":"abroad", "ipa":"/É™ËˆbrÉ”Ëd/", "meaning":"åœ¨åœ‹å¤–", "sentence":"Study abroad...", "syllables":["a","broad"]},
            {"id":3, "day_number":1, "word":"accept", "ipa":"/É™kËˆsept/", "meaning":"æ¥å—", "sentence":"Accept apology...", "syllables":["ac","cept"]},
            {"id":4, "day_number":2, "word":"accident", "ipa":"/ËˆÃ¦ksÉªdÉ™nt/", "meaning":"æ„å¤–", "sentence":"Car accident...", "syllables":["ac","ci","dent"]}
        ]

    def export_to_json(self, data, filename="pet_vocab_db.json"):
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ… æˆåŠŸå°å‡º {len(data)} ç­†è³‡æ–™è‡³ {filename}")

if __name__ == "__main__":
    processor = PetVocabProcessor()
    
    # è«‹ç¢ºèªé€™è£¡çš„æª”åè·Ÿæ‚¨æ¡Œé¢ä¸Šçš„æª”æ¡ˆä¸€æ¨¡ä¸€æ¨£
    docx_filename = "æ›´æ–°ç‰ˆPET28å¤©.docx" 
    
    final_data = processor.parse_docx(docx_filename)
    
    if final_data:
        processor.export_to_json(final_data)
        print("å®Œæˆï¼è«‹æ‰“é–‹ pet_vocab_db.json è¤‡è£½å…§å®¹ã€‚")